# 비전문가가 궁금해서 살짝(?) 파본 LLM 내부 동작 원리 

해당 글은 백엔드 개발자의 관점에서 작성된 글로, LLM 전문가의 시각과는 다를 수 있습니다.  
내용 중 오류를 발견하시면 언제든 피드백 부탁드립니다.

## LLM 내부 동작 원리 6단계

- 1단계: Tokenization (프롬프트를 토큰으로 분리하고 고유 ID 매핑하기)
- 2단계: Embedding (토큰화된 숫자 ID를 의미를 가진 벡터로 변환하기)
- 3단계: Positional Encoding (단어의 순서를 파악하기 위해 위치 정보 더하기)
- 4단계: Transformer and Attention (문맥 관계를 파악하고 각 단어의 표현을 정제하기)
- 5단계: Prediction (다음 토큰 예측하기)
- 6단계: Decoding & Loop (디코딩 및 반복으로 문장 완성하기)

## 1단계: Tokenization

사용자의 프롬프트를 LLM이 이해할 수 있는 최소 단위인 **토큰(Token)** 으로 분리하는 단계입니다. 이 단계는 JSON 문자열을 파싱하여 객체로 만드는 것과 비슷합니다.
- 예를 들어, "LLM의 원리"라는 문장은 `['LLM', '의', ' ', '원리']` 와 같이 의미 있는 단위로 쪼개집니다.
- 각 토큰은 고유한 정수 ID에 매핑됩니다. (예: `[73, 12, 5, 96]`)

<figure><img src="../img/llm-for-developer/llm-tokenizers.png" alt=""><figcaption></figcaption></figure>

reference: https://blog.cubed.run/tokenizer-in-llm-060b1a35694b > `직접 이미지 만들기`

✅ **토큰화(Tokenization)**

토큰화는 LLM이 문장을 이해하기 위해 **의미 있는 최소 단위로 쪼개는 과정**입니다. 마치 문장을 읽을 때 단어 단위로 끊어 읽는 것과 같습니다. 하지만 LLM은 사람과 달라서, 사전에 없는 단어가 나오면 그 단어를 **더 작은 단위로 쪼개서 이해**합니다.
- 예를 들어 "인공지능"이라는 단어는 학습 데이터에 따라 "인공"과 "지능"이라는 두 개의 토큰으로 나뉠 수 있습니다.

Gemini의 경우 토큰화를 위해 [SentencePiece](https://github.com/google/sentencepiece)라는 tokenizer를 사용하고 있습니다. `SentencePiece`가 기존 tokenizer들과 다른 몇 가지의 중요한 차이점과 토큰이 고유한 정수 ID에 매핑되는 과정을 재현해 보겠습니다.
- **언어 중립적**: 공백을 기준으로 단어를 나누지 않고, 문장을 유니코드 문자들의 연속으로 보고, 가장 자주 함께 등장하는 글자들을 통계적으로 묶어 하나의 토큰으로 생성
  - 한국어처럼 조사가 단어에 붙어 쓰이거나 공백의 의미가 크지 않은 언어를 처리하는 데 매우 효과적
- **Subword 기반**: 어휘 사전에 없는 새로운 단어나 긴 단어가 나오면, 이를 더 작은 의미 단위(Subword)로 분해

```python
# pip install sentencepiece
import sentencepiece as spm

# --- 훈련 데이터 준비 ---
training_data = """제미나이는 구글이 개발한 인공지능 언어 모델입니다.
LLM 내부 동작 원리가 궁금하지 않나요?
LLM 내부 동작 원리를 함께 알아보아요.
"""

with open("sample-data.txt", "w", encoding="utf-8") as f:
    f.write(training_data)

# --- 1. 모델 훈련 ---
# SentencePiece 모델 훈련
# 'sample_tokenizer.model', 'sample_tokenizer.vocab' 파일이 생성
spm.SentencePieceTrainer.train(
    '--input=sample-data.txt ' # 훈련시킬 데이터 파일
    '--model_prefix=sample_tokenizer ' # 생성될 모델 파일의 이름
    '--vocab_size=133 ' # 단어 집합의 크기 (어휘의 총 개수)
    '--model_type=bpe' # 모델 타입 (bpe, unigram ..)
)

# --- 2. 훈련된 모델로 토큰화 실행 ---
sp = spm.SentencePieceProcessor()

# 훈련된 모델 파일 로드
sp.load('sample_tokenizer.model')

# 테스트할 문장
sentence1 = "나는 LLM 내부 동작 원리를 공부한다."

# 문장을 토큰으로 분리
# _(언더바)기호는 띄어쓰기(공백)를 의미
tokens1 = sp.encode_as_pieces(sentence1)
print(tokens1) # ['▁', '나', '는', '▁LLM', '▁내부', '▁동작', '▁원리를', '▁', '공', '부', '한', '다', '.']

# 문장을 숫자 ID로 변환
ids1 = sp.encode_as_ids(sentence1)
print(ids1) # [89, 93, 113, 11, 8, 9, 44, 89, 107, 97, 131, 116, 91]

# 숫자 ID를 다시 문장으로 복원
decoded_sentence = sp.decode_ids(ids1)
print(decoded_sentence) # 나는 LLM 내부 동작 원리를 공부한다.
```

`SentencePieceTrainer.train()` 함수에서는 훈련 데이터 파일의 내용을 통계적으로 분석하여, 어떤 글자들을 한 묶음(토큰)으로 만들지 결정하고, 그 규칙을 분해 규칙 파일(`.model`)에 저장합니다. 어휘 사전 파일(`.vocab`)에는 생성된 토큰 목록과 그 점수가 저장됩니다.

```text
...
개발	-49
구글	-50
궁금	-51
내부	-52
동작	-53
리가	-54
리를	-55
...
```

이처럼 LLM이 실시간으로 요청이 들어올 때마다 사용자 입력을 훈련하지는 않고, 이 과정은 `훈련`(Training)과 `추론`(Inference)이라는 두 단계로 명확하게 나뉘어 동작합니다.

**Training Phase**
* 인공지능 언어 모델 개발사(Google, OpenAI 등)가 **단 한 번, 대규모로 수행하는 과정**
* 이 단계에서 수십 테라바이트에 달하는 방대한 텍스트 데이터로 토크나이저를 학습시켜 **완성된 'vocabulary(.vocab)'와 '모델(.model)'** 을 생성

**Inference Phase**
* **사용자가 질문을 할 때마다 일어나는** 동작
* LLM은 이미 만들어진 고정된 tokenizer를 **단순히 메모리에 로드**해서 사용
* 사용자의 문장을 이 규칙에 따라 즉시 토큰으로 변환하고 응답을 생성

✋🏼 **모델 타입? BPE?, ULM?**

`BPE`(Byte Pair Encoding)가 빈도수가 높은 문자 쌍을 병합하는 'Bottom-up' 방식이라면, `ULM`(Unigram Language Model)은 반대로 전체 단어에서 시작하여 중요도가 낮은 서브워드를 제거하는 'Top-down' 방식에 가깝습니다.

1️⃣ BPE 기본 원리
- 텍스트 내의 모든 개별 문자를 **초기 어휘**로 설정
- 현재 어휘로 구성된 텍스트에서 가장 빈번하게 함께 나타나는 **문자 쌍 찾기**
- 가장 빈번한 문자 쌍을 하나의 새로운 **서브워드 토큰으로 병합**(예: "l o w"에서 'o'와 'w'가 자주 나타나면 'ow'로 병합)
- 새로운 토큰을 어휘에 추가하고, 미리 정의된 어휘 크기에 도달하거나 더 이상 병합할 유의미한 쌍이 없을 때까지 **2단계와 3단계를 반복**

이 과정을 통해 자주 나타나는 문자 조합은 긴 서브워드가 되고, 희귀한 단어나 새로운 단어는 여러 개의 짧은 서브워드로 분리됩니다.

2️⃣ ULM 기본 원리
- 매우 큰 초기 **어휘 집합** 생성
- 각 서브워드 토큰이 텍스트에 나타날 확률을 계산(해당 서브워드의 빈도수 기반)
- 주어진 단어를 여러 서브워드로 분절할 수 있는 모든 가능한 경우의 수를 고려
  - "unigram"이라는 단어가 있다고 가정했을 때, un + igram, uni + gram, u + ni + gram 등 다양한 분절이 가능
  - 이 중 어떤 분절 조합이 가장 높은 확률을 가지는지 계산하여 선택
- 어휘 집합의 크기를 줄여나가는 과정
  - 전체 확률 분포에 미치는 영향이 가장 작은 서브워드를 제거
  - 이 과정을 미리 정해둔 vocab_size에 도달할 때까지 반복

## 2단계: Embedding

임베딩은 토큰화된 숫자 ID를 **의미를 가진 다차원 공간의 좌표인 벡터**로 변환하는 단계입니다. 단순히 숫자를 다른 숫자로 바꾸는 것이 아니라, 단어의 의미와 뉘앙스를 수치적으로 표현하는 핵심 단계입니다.

**Embedding Table**: 토큰 ID와 벡터를 짝지어 놓은 좌표 사전(임베딩 테이블)
- 예를 들어, 12833번 단어에 해당하는 768차원의 좌표 [0.12, -0.45, 0.89, ...]가 미리 저장되어 있습니다. 
- 이 좌표값들은 수많은 데이터를 학습하며 얻은 결과물입니다.

**Semantic Proximity**: 이 좌표 공간에서 비슷한 의미를 가진 단어들은 서로 가까운 위치에, 관련 없는 단어들은 먼 위치에 존재합
- '자동차'와 '자전거'의 좌표는 비교적 가깝고, '자동차'와 '행복'의 좌표는 매우 멀다.
- 이러한 거리(유사도)를 통해 단어 간의 관계를 수학적으로 이해하고 추론할 수 있습니다.

**문맥적 유연성**: 임베딩은 단어 하나뿐만 아니라 문장이나 문단 전체에 대해서도 생성될 수 있습니다. 
- 이를 통해 글 전체의 종합적인 의미를 하나의 벡터로 압축하여 표현할 수 있습니다.

한국어 특화 모델인 [ko-sentence-transformers](https://github.com/jhgan00/ko-sentence-transformers)를 로컬에 직접 다운로드하고, 텍스트를 의미가 담긴 벡터로 변환하기 위해 [sentence-transformers](https://www.sbert.net/) 라이브러리를 활용하여 Embedding 단계를 재현해 보겠습니다.  

> `직접 이미지 만들기`

```python
# pip install -U sentence-transformers
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity

# --- 1. Hugging Face Hurb에서 한국어 특화 모델을 로컬 환경에 다운로드 후 메모리에 로드 ---
try:
    model = SentenceTransformer('jhgan/ko-sroberta-multitask')
except Exception as e:
    print(f"모델 로딩 중 오류가 발생했습니다: {e}")
    exit()

# --- 2. 임베딩으로 변환할 단어들을 정의 ---
words = ["자동차", "자전거", "행복"]

# --- 3. 모델을 사용하여 각 단어를 벡터로 변환 ---
# 내부적으로 토큰화와 임베딩을 수행
embeddings = model.encode(words)

# --- 4. 생성된 벡터의 형태와 일부 값 확인 ---
print(f"'{words[0]}' 단어의 임베딩 벡터 차원: {embeddings[0].shape}")
print(f"'{words[0]}' 단어의 임베딩 벡터 일부: {embeddings[0][:5]}\n")

# --- 5. 단어 간의 코사인 유사도를 계산하여 의미적 거리 확인 ---
# 결과값이 1에 가까울수록 의미가 가깝다는 의미
sim_car_bicycle = cosine_similarity([embeddings[0]], [embeddings[1]])
sim_car_happiness = cosine_similarity([embeddings[0]], [embeddings[2]])
print(f"'{words[0]}'와(과) '{words[1]}'의 코사인 유사도: {sim_car_bicycle[0][0]:.4f}")
print(f"'{words[0]}'와(과) '{words[2]}'의 코사인 유사도: {sim_car_happiness[0][0]:.4f}")
```

```text
'자동차' 단어의 임베딩 벡터 차원: (768,) # 벡터에 들어있는 수자의 개수(예를 들어 RGB 이미지의 경우 3차원)
'자동차' 단어의 임베딩 벡터 일부: [ 0.04892848  0.2749219   0.15132347 -0.5050876  -0.23192444] # LLM이 학습한 '자동차'의 의미를 수치적으로 표현한 벡터

'자동차'와(과) '자전거'의 코사인 유사도: 0.8315 # '탈 것'이라는 공통된 의미로 높은 유사도
'자동차'와(과) '행복'의 코사인 유사도: 0.1854 # 의미적 관련성이 없어 낮은 유사도
```

**코사인 유사도 샘플**

<figure><img src="../img/llm-for-developer/embedding-example-1.png" alt=""><figcaption></figcaption></figure>

**차원 축소 샘플**

<figure><img src="../img/llm-for-developer/embedding-example-2.png" alt=""><figcaption></figcaption></figure>

## 3단계: Positional Encoding

LLM의 핵심인 Attention 메커니즘(문장 속에서 어떤 단어가 다른 단어에 얼마나 영향을 미치는지 수치화하여, 문맥을 정확하게 파악)은 **문장 내 단어들의 관계를 파악**하는 데 매우 뛰어나지만, 
- "나는 사과를 먹었다." (과일)
- "나는 너에게 사과했다." (용서)

**어떤 단어가 먼저 나왔는지 순서를 모른다는 한 가지 단점**이 있습니다. 이 때문에 "고양이가 강아지를 이겼다"와 "강아지가 고양이를 이겼다"를 구분하지 못하는 문제가 생깁니다. 

`Positional Encoding`은 바로 이 문제를 해결하기 위해 각 단어의 순서 정보가 담긴 고유한 벡터를 만들어 단어의 임베딩 벡터에 더해주는 단계입니다.
- 최종 입력 벡터 = Word Embedding Vector(의미) + Positional Encoding Vector(순서)

⚠️ 잠깐! 어떻게 위치마다 고유한 벡터를 만들까 ⁉️
- 가장 고전적이고 유명한 방법은 `sine`, `cosine` 함수를 이용하는 방법
- 각 단어의 위치와 벡터의 차원에 따라 서로 다른 주파수를 가진 sin, cos 값을 계산하여 고유한 위치 벡터를 생성

```text
수식:
PE(pos, 2i)   = sin(pos / 10000^(2i / d_model))  # 짝수 인덱스 차원
PE(pos, 2i+1) = cos(pos / 10000^(2i / d_model))  # 홀수 인덱스 차원

- d_model: 모델의 '크기'를 나타내는 임베딩 벡터의 총 차원 수
- 10000: 다양한 주파수를 만들기 위해 스케일링을 위한 상수
- pos: 현재 단어의 시퀀스 내 위치
- i: 임베딩 벡터의 차원 인덱스 (0 ~ d_model-1)
```

👉🏻  Final Embedding = Word Embedding Vector + Positional Encoding Vector

```text
고양이가 소파 위에서 잠을 잡니다.

   [0.6525 0.266  0.5645 0.7149 0.6867]... ('고양이' 의미 벡터 일부)
+  [0. 1. 0. 1. 0.]... ('고양이' 0번째 위치 벡터 일부)
----------------------------------------------------------------
   [0.6525 1.266  0.5645 1.7149 0.6867]... ('고양이'의 최종 임베딩 일부)

   [0.8779 0.2883 0.0404 0.0478 0.6339]... ('잠을' 의미 벡터 일부)
+  [-0.7568 -0.6536 -0.6572 -0.7537 -0.5486]... ('잠을' 3번째 위치 벡터 일부)
----------------------------------------------------------------
   [ 0.1211 -0.3653 -0.6168 -0.7059  0.0853]... ('잠을'의 최종 임베딩 일부)
```

> `직접 이미지 만들기`

## 4단계: Transformer and Attention

복잡한 문장을 이해하고 생성하는 기능을 가능하게 한 핵심 기술이 `Transformer`라는 **신경망 구조**와 그 안에 있는 `Attention`이라는 **메커니즘**
- `Transformer`는 LLM의 효율적이고 강력한 병렬 처리 **두뇌** 구조
  - 문장 전체의 단어들을 한 번에 병렬로 처리하여 빠른 학습 능력
- `Attention`은 두뇌를 이용해 문장 내에서 중요한 부분에 **집중**하고 **문맥을 파악**하는 핵심 기술
  - 문장 내에서 모든 다른 단어들과의 관련도에 집중함으로써, 복잡한 문맥과 다의어를 더 정확하게 이해
  - 아무리 문장이 길어져도 멀리 떨어진 단어들 사이의 관계를 효과적으로 파악

`Transformer`의 핵심적인 구성 요소는 크게 **셀프 어텐션(Self-Attention) 메커니즘**과 **피드 포워드 신경망(Feed-Forward Neural Network, FFN)** 으로 나눌 수 있습니다.  
또한, `Transformer`는 **인코더**와 **디코더**라는 두 가지 주요 블록으로 구성되어 있는데, 이 각 블록 안에 셀프 어텐션과 피드 포워드 신경망이 반복적으로 나타납니다.

👉🏻 **인코더 레이어**
- `Multi-Head Self-Attention`: 문장 내 단어들 간의 **관계를 파악**하여, 각 단어가 **문맥에서 어떤 의미**를 가지는지 이해하는 메커니즘 > 현재 단어가 문장 내 다른 단어들과 얼마나 관련이 있는지를 탐색하는 과정
  - **Multi-Head**: 하나의 셀프 어텐션을 사용하는 것이 아니라, 여러 개의 독립적인 '어텐션 헤드'를 동시에 사용. 각 헤드는 단어들 간의 다른 종류의 관계(예: 주어-동사 관계, 명사-형용사 관계 등)를 학습하여, 다양한 관점에서 문맥을 이해할 수 있도록 하고, 이렇게 다양한 관점에서 얻은 정보들을 나중에 하나로 결합
- `Feed-Forward Neural Network`: 셀프 어텐션 레이어를 통과한 벡터를 받아서, 각 단어의 벡터를 더 풍부한 특징 표현으로 생성 > 각 단어가 가진 잠재적인 정보를 더욱 명확히 다듬는 과정

👉🏻 **디코더 레이어**
- `Masked Multi-Head Self-Attention`: 디코더는 단어를 순차적으로 생성해야 하므로, 현재 단어를 예측할 때 미래의 단어(아직 생성되지 않은 단어)를 참조하지 못하도록 '마스킹(Masking)'을 적용한 셀프 어텐션
- `Encoder-Decoder Attention`: 디코더에만 있는 독특한 부분으로, 인코더의 출력(입력 문장의 정보)을 참조하여 번역이나 요약 같은 작업을 수행할 때 입력 문장과 생성할 문장 사이의 관계를 파악
- `Feed-Forward Neural Network`: 앞선 어텐션 레이어들의 출력을 받아 각 단어별 특징을 강화

> 요약하면, `Transformer`는 기본적으로 **Self-Attention 메커니즘**으로 문맥 관계를 파악하고, **Feed-Forward Neural Network** 으로 각 단어의 표현을 정제하고 강화하는 과정을 반복하며 텍스트를 이해하고 생성합니다. 

> `직접 이미지 만들기`

## 5단계: Prediction

문맥을 파악한 최종 벡터를 바탕으로, **다음에 올 가장 확률이 높은 단어(토큰)를 예측**합니다.

모델은 어휘 사전(.vocab) 있는 모든 단어에 대해 **다음 순서에 올 확률을 계산**합니다. 이 확률 분포에서 하나의 토큰을 선택합니다. (예: 'LLM의 내부 동작 원리는' 다음에 '매우', '복잡', '합니다' 등의 토큰이 높은 확률을 가짐)

지금까지 모든 과정을 거쳐 문맥을 완벽히 파악한 벡터가 준비되었습니다. 
- 1단계: Tokenization (프롬프트를 토큰으로 분리하고 고유 ID 매핑하기)
- 2단계: Embedding (토큰화된 숫자 ID를 의미를 가진 벡터로 변환하기)
- 3단계: Positional Encoding (단어의 순서를 파악하기 위해 위치 정보 더하기)
- 4단계: Transformer and Attention (문맥 관계를 파악하고 각 단어의 표현을 정제하기)

이제 LLM은 이 벡터를 가지고 **"그래서, 다음에 올 단어는 무엇일까?"** 라는 질문에 답해야 합는데, 이 단계는 크게 두 부분으로 나뉩니다.

1️⃣ **확률 계산 - 모든 단어에 점수 매기기**
- LLM은 자신이 알고 있는 수만 개의 모든 단어(토큰)들을 후보로 올려놓고, **다음에 등장할 확률을 각각 계산**
  - **등장 가능성 점수(Logits) 생성**: 문맥을 파악한 최종 벡터를 이용해 어휘 사전의 모든 단어에 대해 '등장 가능성 점수(Logit)'를 매김
  * **확률(Softmax) 변환**: 이 점수들을 보기 쉽게 **확률(%)로 변환**. 모든 단어의 확률을 합하면 1(100%)
- 이제 모델은 "다음에 '매우'가 올 확률은 15%, '복잡'이 올 확률은 12%..." 와 같은 확률 분포표를 보유

2️⃣ **샘플링(Sampling) - 확률에 따라 단어 선택하기**
- 가장 확률 높은 단어만 계속 선택하면 매우 예측 가능하고 지루한 문장이 생성. 그래서 LLM은 더 창의적인 문장을 만들기 위해 다양한 **샘플링 전략**을 사용.
  - **Greedy Search**: 무조건 확률 1등 단어만 선택
  - **Top-K Sampling**: 확률 순위가 높은 K개(예: 50개)의 단어만 확률에 따라 선택
  - **Top-P (Nucleus) Sampling**: 확률의 합이 P(예: 95%)가 될 때까지 상위권 단어들을 후보로 올리고, 모델이 다음에 올 단어를 확신할수록 후보가 적어지고, 불확실할수록 후보가 많아지는 유연한 방식입니다. (Gemini와 같은 최신 모델들이 주로 사용하는 핵심 전략)
  - **Temperature**: '예측 불가능성'을 조절. 온도가 높으면(\>1.0) 확률이 낮은 단어도 과감하게 뽑아 창의적인 문장을 생성하고, 낮으면(\<1.0) 확률 높은 단어 위주로 뽑아 안정적인 문장을 생성
- 이 과정을 통해 한 단어를 선택하고, 그 단어를 다시 입력에 추가하여 다음 단어를 예측하는 과정을 반복하면 비로소 하나의 문장이 완성

<figure><img src="../img/llm-for-developer/prediction.png" alt=""><figcaption></figcaption></figure>

ref. https://medium.com/@akash.kesrwani99/understanding-next-token-prediction-concept-to-code-1st-part-7054dabda347 > `직접 이미지 만들기`

## 6단계: Decoding & Loop














예측된 토큰을 다시 입력값에 추가하고, 4~6단계를 반복하여 다음 단어를 계속 생성합니다. 이 과정을 `[END]` 토큰이 생성될 때까지 반복하여 최종적으로 완성된 문장을 사용자에게 반환합니다.

이 단계는 새로운 계산을 하는 것이 아니라, 5단계에서 설명한 '다음 토큰 예측' 과정을 **자동으로 반복시켜 문장을 완성하는 엔진**입니다. LLM이 긴 글을 쓸 수 있는 비결이 바로 여기에 있습니다.

이 과정을 \*\*자동 회귀(Autoregressive)\*\*라고 부르며, 마치 혼자서 '릴레이 소설'을 쓰는 것과 같습니다.

#### '예측하고 이어붙이기' 루프(Loop)

1.  **예측 (Predict)**: 현재까지의 문장을 보고 다음 단어 하나를 예측합니다. (5단계 과정)

    * `인공지능은 인류의` -\> **`미래`**

2.  **추가 (Append)**: 예측된 단어를 원래 문장 끝에 이어붙여 새로운 입력값을 만듭니다.

    * 새로운 입력: `인공지능은 인류의 미래`

3.  **반복 (Loop)**: 이제 이 길어진 문장을 가지고 다시 1번으로 돌아가 다음 단어를 예측합니다.

    * `인공지능은 인류의 미래` -\> **`를`**
    * 새로운 입력: `인공지능은 인류의 미래를`
    * `인공지능은 인류의 미래를` -\> **`바꿀`**
    * ...

이 **'예측-추가-반복'** 루프는 다음 두 가지 조건 중 하나를 만족할 때까지 계속됩니다.

* **[EOS] 토큰 등장**: 모델이 문장의 끝을 의미하는 특수 토큰(End-Of-Sentence)을 생성할 때
* **최대 길이 도달**: 우리가 미리 설정한 최대 단어 개수(예: 100개)에 도달할 때

#### 디코딩 (Decoding)

루프가 모두 끝나고 최종적으로 생성된 **숫자 ID들의 배열** `[3141, 912, 114, ...]`을 사람이 읽을 수 있는 **하나의 완성된 텍스트**로 다시 변환하는 과정을 '디코딩'이라고 합니다.




















## 더 정확한 답변을 얻기 위한 6가지 팁


위 동작 원리를 이해하면 LLM을 단순한 채팅봇이 아닌, **프로그래밍 가능한 언어 인터페이스**로 활용할 수 있습니다.

1.  **명확한 역할(Persona)과 형식 지정**: 프롬프트 시작에 "당신은 10년 차 백엔드 개발자입니다. Java Spring 코드로 답변해주세요."와 같이 역할을 부여하세요. 이는 5단계(예측)에서 모델이 선택할 단어의 범위를 효과적으로 좁혀줍니다.

2.  **풍부하고 구체적인 컨텍스트 제공**: "코드에 에러가 나" 보다는 "Spring Boot 3.1.5 버전에서 JPA를 사용 중인데, `NullPointerException`이 발생했습니다. 아래는 관련 코드와 에러 로그입니다."와 같이 구체적인 정보를 제공하세요. 4단계(어텐션)에서 모델이 문제의 핵심에 더 잘 '집중'할 수 있게 합니다.

3.  **예시(Few-shot)를 통한 출력 유도**: 원하는 결과물의 예시를 한두 개 보여주면, LLM이 출력 형식을 더 정확하게 학습합니다. 이는 모델 전체를 재학습시키는 것이 아니라, 특정 요청에 대한 어텐션 가중치를 효과적으로 유도하는 방법입니다.
    * `질문: Python 리스트를 정렬하는 방법은?`
    * `답변 (예시): list.sort() 또는 sorted(list)를 사용합니다.`
    * `질문: Java 리스트를 정렬하는 방법은?`
    * `답변: (LLM이 형식에 맞춰 답변할 확률이 높아짐)`

4.  **복잡한 작업은 단계별로 분해**: 하나의 거대한 프롬프트로 모든 것을 해결하려 하지 마세요. "A 데이터를 분석해서, 그래프를 그리고, 보고서를 써줘" 보다는 아래와 같이 작업을 나누어 요청하는 것이 훨씬 효과적입니다.
    * `1. A 데이터의 주요 특징을 분석해줘.`
    * `2. 분석 결과를 바탕으로 막대그래프를 그리는 Python 코드를 작성해줘.`
    * `3. 위 내용을 종합해서 보고서 초안을 작성해줘.`

5.  **부정문 대신 긍정문으로 지시**: "JSON 형식 외에는 출력하지 마" 보다는 "반드시 RFC 8259 표준을 준수하는 JSON 형식으로만 출력해줘"와 같이 긍정적이고 명확한 지시가 더 좋은 결과를 낳습니다.

6.  **결과를 비판적으로 검토하고 되먹임(Feedback)**: 첫 답변이 만족스럽지 않다면, "그 답변은 이러이러한 점에서 틀렸어. 그 점을 수정해서 다시 설명해줘."와 같이 구체적인 피드백을 주며 대화를 이어가세요. 이는 6단계(반복) 과정을 개발자가 직접 제어하며 원하는 결과로 유도하는 것과 같습니다.








https://anthropic.skilljar.com/claude-with-the-anthropic-api/287726