# Spring Batch Chunk

스프링 배치를 통해 대량의 데이터를 여러 번 처리해야 했었는데요. 그 과정에서 발생했던 **OOM(Out Of Memory)** 문제를 어떤 방식으로 풀어냈는지 공유하고자 합니다.

## 문제의 시작

원장 통계 데이터 구조를 변경하기 위해, 17년도부터 25년도까지 약 9년치 원장 데이터에 대한 새로운 통계를 생성하는 작업을 진행하게 되었어요. 

트래픽이 가장 많은 채널에 대한 하루치 원장 데이터만 해도 대략 250만 건이 되었는데, 한달치면 약 7,500만 건, 일년치면...

방대한 양의 운영 데이터에 변경이 일어나는 작업이다보니, 작업 중간중간 데이터 정합성을 확인하며 진행하기 위해 한달 단위로 나눠서 작업을 진행하는 전략을 세우게 되었어요.

한달 단위로 나누더라도 한 번의 배치 작업에 7,500만 건의 원장 데이터가 사용되게 되므로, 배치 안에서도 하루씩 분할해서 처리가 되도록 구현하는 전략을 추가하게 되었어요.

## Partitioner 사용하기

